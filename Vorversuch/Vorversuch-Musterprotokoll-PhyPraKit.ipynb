{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f39727-e17c-4872-a16e-0da5adab70ef",
   "metadata": {},
   "source": [
    "# Fakultät für Physik\n",
    "\n",
    "## Physikalisches Praktikum P1 für Studierende der Physik\n",
    "\n",
    "Praktikumsvorversuch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Datenverarbeitung am Beispiel des Pendels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3702e-3be5-44bd-8a9b-cf9b1a1433b5",
   "metadata": {},
   "source": [
    "Name: Mustermann Vorname: Martin E-Mail: martin.mustermann@student.kit.edu\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "&\\\\\n",
    "&\\\\\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Name: Musterfrau Vorname: Martina E-Mail: martina.musterfrau@student.kit.edu\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Gruppennummer: Mo99\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Betreuer: Roger Wolf\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Versuch durchgeführt am: 31.10.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78848a-50e2-4821-a5e8-e8e1e271be24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Beanstandungen:**\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "&\\\\\n",
    "\\end{split}\n",
    "%\\text{\\vspace{10cm}}\n",
    "\\end{equation*}\n",
    "\n",
    "<br>\n",
    "Testiert am: __________________ Testat: __________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f54c3e-9db9-4880-af22-70a8ddcd2661",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "\n",
    "## Aufgabe 1: Umgang mit großen Datensätzen\n",
    "\n",
    "**Hinweise zu allen hier durchzuführenden Messungen finden Sie in der Datei [Hinweise-Aufgabe-1.md](https://gitlab.kit.edu/kit/etp-lehre/p1-praktikum/students/-/tree/main/Vorversuch/doc/Hinweise-Aufgabe-1.md).**\n",
    "\n",
    " * Öffnen Sie die Dateien ```data_raw.csv``` und ```data_down_sampled.csv``` per Doppelklick und untersuchen die Spalten und Zeilen. \n",
    " * Geben Sie die Größe der Dateien in MB an. \n",
    " * Stellen Sie die einzelnen Spalten jeweils in einem Diagramm, als Funktion der Zeit $t$ dar.\n",
    " \n",
    " Verwenden Sie für alle weiteren Untersuchung die Datei ```data_down_sampled.csv```. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea59c2e4-3f9b-41c0-b3f6-9a25789f2dfb",
   "metadata": {},
   "source": [
    "## Lösung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19542019-6492-4174-9021-deedbb9d9375",
   "metadata": {
    "tags": []
   },
   "source": [
    " * Die *app* phyphox exportiert die Daten in fünf Spalten mit den eindeutigen Bezeichnungen:\n",
    " \n",
    "   - Time (s)\n",
    " \n",
    "   - Linear Acceleration x (m/s^2)\n",
    "\n",
    "   - Linear Acceleration y (m/s^2)\n",
    "\n",
    "   - Linear Acceleration z (m/s^2)\n",
    "\n",
    "   - Absolute acceleration (m/s^2)\n",
    "\n",
    " * Die Datei ```data_raw.csv``` hat eine Größe von $2.4\\,\\mathrm{MB}$ und 32304 Zeilen (ohne Überschriften). \n",
    "\n",
    " * Die Datei ```data_down_sampled.csv``` hat eine Größe von $13\\,\\mathrm{kB}$ und 171 Zeilen. \n",
    "\n",
    " * Es handelt sich um eine **Reduktion der Datenmenge um einen Faktor von 190**. Die Reduktion über den Faktor 10 hinaus ergibt sich daraus, dass nur ein Zeitfenster von sample 500 bis sample 2200 ($5{-}22\\,\\mathrm{s}$ nach Beginn der Datennahme) verwendet wurde. \n",
    "\n",
    " * Eine Inspektion der ausgewählten Daten aus der Datei ```data_down_sampled.csv``` ist in **Abbildung 1** gezeigt: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b1829-04d0-4627-8110-fda0ee18ef41",
   "metadata": {},
   "source": [
    "Als ersten Schritt sollen die Daten visualisiert werden. Dies erledigen Sie mit dem Skript\n",
    "*plot_csv* im Verzeichis *opt/conda/bin*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796ddc48-76a5-4dac-b567-6a446922074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /opt/conda/bin/plotCSV.py data_down_sampled.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac32cbc-addb-4aaf-b9b3-5bf9d70d2a64",
   "metadata": {},
   "source": [
    "Alternativ können Sie auch den folgenden *Python*-Code ausführen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee063dbb-768b-4400-9c7a-4172b51d6e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CODE TO CREATE ABBILDUNG 1\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def subplot(ax, df, column):\n",
    "    \"\"\"\n",
    "    Create a single subplot per column vs. time from a dataframe.\n",
    "    \"\"\"\n",
    "    ax.plot(\"Time (s)\", column, data=df, color=\"darkblue\")\n",
    "    ax.set_title(\"N=%d\"%df.shape[0]) # Number of points in plot\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel(\"AU\")\n",
    "\n",
    "def plot(df, **kwargs):\n",
    "    \"\"\"\n",
    "    Create a figure for quick inspection of the csv-file.\n",
    "    \n",
    "    Creates a 4x2 figure for all columns that are provided by the original csv-\n",
    "    file. The upper row shows the raw data; for the second row the raw data are \n",
    "    smoothed through a running mean with a user-defined window size of 10. The \n",
    "    figure is saved in pdf format.\n",
    "    \"\"\"\n",
    "    # Set up the Axes for this example\n",
    "    fig, ax = plt.subplots(2, 4, figsize=(12., 6.), constrained_layout=True)\n",
    "    # Columns of the original csv \n",
    "    subplot(ax[0][0], df, \"Linear Acceleration x (m/s^2)\")\n",
    "    subplot(ax[0][1], df, \"Linear Acceleration y (m/s^2)\")\n",
    "    subplot(ax[0][2], df, \"Linear Acceleration z (m/s^2)\")\n",
    "    subplot(ax[0][3], df, \"Absolute acceleration (m/s^2)\")\n",
    "    # Columns after smoothing\n",
    "    subplot(ax[1][0], df, \"Convoluted x\")\n",
    "    subplot(ax[1][1], df, \"Convoluted y\")\n",
    "    subplot(ax[1][2], df, \"Convoluted z\")\n",
    "    subplot(ax[1][3], df, \"Convoluted abs\")\n",
    "    print(\"Saving figure as \", kwargs[\"filename\"].replace(\".csv\", \".pdf\"))\n",
    "    plt.savefig(\"./\"+kwargs[\"filename\"].replace(\".csv\", \".pdf\"))\n",
    "    plt.show()\n",
    "\n",
    "def main(**kwargs):\n",
    "    if not path.isfile(kwargs[\"filename\"]):\n",
    "        print(\"Could not find file %s. Please check filename and location\"%kwargs[\"filename\"])\n",
    "        exit() \n",
    "    print(\"Reading from file:\", kwargs[\"filename\"])\n",
    "    # Read csv as pandas dataframe     \n",
    "    df = pd.read_csv(kwargs[\"filename\"])\n",
    "    # Apply a running mean smoothing\n",
    "    df[\"Convoluted x\"] = np.convolve(\n",
    "        # This is the column name\n",
    "        df[\"Linear Acceleration x (m/s^2)\"], \n",
    "        np.ones(kwargs[\"w\"])/kwargs[\"w\"], \n",
    "        mode=\"same\"\n",
    "        )\n",
    "    df[\"Convoluted y\"] = np.convolve(\n",
    "        df[\"Linear Acceleration y (m/s^2)\"], \n",
    "        np.ones(kwargs[\"w\"])/kwargs[\"w\"], \n",
    "        mode=\"same\"\n",
    "        )\n",
    "    df[\"Convoluted z\"] = np.convolve(\n",
    "        df[\"Linear Acceleration z (m/s^2)\"], \n",
    "        np.ones(kwargs[\"w\"])/kwargs[\"w\"], \n",
    "        mode=\"same\"\n",
    "        )\n",
    "    df[\"Convoluted abs\"] = np.convolve(\n",
    "        df[\"Absolute acceleration (m/s^2)\"], \n",
    "        np.ones(kwargs[\"w\"])/kwargs[\"w\"], \n",
    "        mode=\"same\"\n",
    "        )\n",
    "    plot(df, **kwargs)\n",
    "\n",
    "main(\n",
    "    # File name\n",
    "    filename=\"data_down_sampled.csv\",\n",
    "    # Window size for running mean\n",
    "    w=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded12786-f615-4329-817d-bfee8400360b",
   "metadata": {},
   "source": [
    "**Abbildung 1** (Inspektion der ausgewählten Daten aus der Datei `data_down_sampled.csv`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f33c4a-40b1-4513-b5a1-922ffb9bdb4a",
   "metadata": {},
   "source": [
    "**Diskussion:**\n",
    "\n",
    " * Der (reduzierte) Datensatz umfasst **10 Perioden der Schwingung**. Für uns von Relevanz ist die Beschleunigung in $x$-Richtung, die auch bei weitem die größten Auslenkungen mit dem regelmäßigsten Verhalten aufweist. \n",
    "\n",
    " * Die Beschleunigung in $y$-Richtung zeigt eine Grundschwingung, die mit der Bewegung in $x$-Richtung korreliert ist. Das kann ein Hinweis darauf sein, dass das Smartphone nicht ganz plan auf das Pendel montiert war. Die Oberschwingungen rühren vermutlich eher nicht von einem schrägen Antoß des Pendels sondern von der Beschaffenheit und Auflage des Keils her, der in der Keilpfanne der Aufhängung des Pendelaufbaus liegt. \n",
    "\n",
    " * Ein ähnliches Verhalten beobachten wir für die Bewegung in $z$-Richtung, die zunächst überraschend unregelmäßig und in der Amplitude nicht viel größer als die Bewegung in $y$-Richtung ist. Die Oberschwingungen in dieser Bewegung würden wir ebenfalls auf die Beschaffenheit des Keils und der Keilpfanne zurückführen. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa587ba-00e2-4ffe-a28b-8ac1a6bc5979",
   "metadata": {},
   "source": [
    "## Aufgabe 2: Mathematische Pendel\n",
    "\n",
    "**Hinweise zu allen hier durchzuführenden Messungen finden Sie in der Datei [Hinweise-Aufgabe-2.md](https://gitlab.kit.edu/kit/etp-lehre/p1-praktikum/students/-/tree/main/Vorversuch/doc/Hinweise-Aufgabe-2.md).**\n",
    "\n",
    "Zur Bestimmung von $g$ unterlegen wir zunächst das Modell eines [mathematischen Pendels](https://de.wikipedia.org/wiki/Mathematisches_Pendel), woraus sich $g$ wie folgt ableiten lässt:\n",
    "\n",
    "$$\n",
    "g = \\frac{4\\,\\pi^{2}}{T^{2}}\\ell,\n",
    "$$\n",
    "\n",
    "wobei $\\ell$ der Länge des Pendels entspricht. Als Referenzwert für alle weiteren Messungen können Sie den Wert \n",
    "\n",
    "$$\n",
    "g_{\\mathrm{exp}} = (9.809599\\pm0.000034)\\,\\mathrm{m/s^{2}}\n",
    "$$\n",
    "\n",
    "verwenden. Dieser Wert wurde aus der [Global Gravtiy Database des Bureau Gravimetrique International (BGI)](https://ggos.org/item/bgi/) für die Stadt Mannheim (bei $49,49^{\\circ}$ nördlicher Breite und $8,53^{\\circ}$ westlicher Länge auf einer Referenzhöhe von $101\\,\\mathrm{m}$) ausgelesen. \n",
    "\n",
    "### Aufgabe 2.1: Referenzmessung von $T$ \n",
    "\n",
    " * Bestimmen Sie **einen einzelnen Wert** für die Periode $T$ in den Daten. \n",
    " * Überlegen Sie sich eine sinnvolle Unsicherheit $\\Delta T$ und ermitteln Sie $g$ mit entsprechender Unsicherheit $\\Delta g^{(2.1)}$. Bestimmen Sie $\\Delta g^{(2.1)}$ mit Hilfe linearer [Fehlerfortpflanzung](https://de.wikipedia.org/wiki/Fehlerfortpflanzung) nach Gauß. Berücksichtigen Sie dabei auch die Unsicherheit $\\Delta\\ell$.\n",
    " * Vergleichen Sie Ihr Ergebnis, im Rahmen der Unsicherheiten, mit $g_{\\mathrm{exp}}$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f044b-03d1-4c92-bd20-7e01ca5bad87",
   "metadata": {},
   "source": [
    "## Lösung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2374082-8905-4637-96f9-85a04ba267ad",
   "metadata": {},
   "source": [
    "Es gibt einige Alternativen zur Bestimmung der Periodendauer. \n",
    "\n",
    "* Die Einfachste Möglichkeit besteht darin, die Periodendauer aus der obern erzeugten Grafik abzulesen. \n",
    "\n",
    "* Man kann auch die aus der Vorlesung CGDA bekannte Autokorrelation verwenden und die Abstände zwischen den Extrema der Autokorrelationsfunkton bestimmen. \n",
    "   \n",
    "* Als weitere Möglichkeit haben wir die Periode $T$ der Schwingung unten aus der einzelnen Messung eines Nulldurchgangs der Schwingung in $x$-Richtung bestimmt. Die Nullstellen wurden\n",
    "mit dem folgenden Skript bestimmt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1943d-2e78-4a95-b079-28c21d41e44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CODE TO OBTAIN ONE VALUE FOR THE PERIOD T\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "import yaml\n",
    "\n",
    "# Proxy for a histogram fit. Values in {*} should be replaced  \n",
    "HEADSTRING=\\\n",
    "\"\"\"\\\n",
    "# Input data:\n",
    "# input file  : {file}\n",
    "# raw_data    : {raw_data}\n",
    "# -----------------------------------------------------------\n",
    "type: histogram\n",
    "\n",
    "label: Intercepts\n",
    "x_label: 'T (sec)'\n",
    "y_label: 'Density p(T)'\n",
    "\n",
    "n_bins: 30\n",
    "bin_range: [{min}, {max}]\n",
    "\n",
    "model_density_function: |\n",
    "  def normal_distribution(x, mu={mean}, sigma={std}):\n",
    "    return np.exp(-0.5*((x-mu)/sigma)**2)/np.sqrt(2.*np.pi*sigma**2)\n",
    "\n",
    "# Data:\n",
    "\"\"\"\n",
    "\n",
    "def main(**kwargs): \n",
    "    if not path.isfile(kwargs[\"filename\"]):\n",
    "        print(\"Could not find file %s. Please check filename and location\"%kwargs[\"filename\"])\n",
    "        exit() \n",
    "    print(\"Reading from file:\", kwargs[\"filename\"])\n",
    "    # Read csv as pandas DataFrame. Rename coumns to x and f for convenience\n",
    "    # reasons.     \n",
    "    df = pd.read_csv(kwargs[\"filename\"]).rename(\n",
    "                  columns={\n",
    "                      kwargs[\"x_data\"]:\"x\", \n",
    "                      kwargs[\"y_data\"]:\"f\"\n",
    "                  }\n",
    "             ).loc[:, \"x\":\"f\"]\n",
    "    # Find intercept row; a change of sign in f is indicated by \"-1\" when going\n",
    "    # from positive to negative and \"+1\" when going from negative to positive \n",
    "    # values in f(x); pd.diff() returns the difference w.r.t. the previous line \n",
    "    # and nan in case there is none.\n",
    "    df[\"idx\"] = ((df[\"f\"]+df[\"f\"].apply(np.abs))/2/df[\"f\"]).diff()\n",
    "    # Find linearly interpolated intercept in x.\n",
    "    df[\"dx\"] = df[\"idx\"]*(df[\"x\"]-df[\"f\"]/df[\"f\"].diff()*df[\"x\"].diff())\n",
    "    # Reduce df to values>0 and get differences between neighboring rows. Also \n",
    "    # values<0 could be chosen. The restriction to values of the same sign  \n",
    "    # among other reasons is made to obtain the period T and not T/2.\n",
    "    df = pd.DataFrame(df.loc[df[\"dx\"]>0, \"dx\"].diff())\n",
    "    # Dump to yaml in a format as expected from the PhyPraKit tool \n",
    "    # \"run_phyFit.py\" for a histogram fit. The name of the output file is \n",
    "    # the same as for the input file, only the ending is replaced from \n",
    "    # \".csv\" to \"_intercepts.yaml\".\n",
    "    output_name=\"./yaml/\"+kwargs[\"filename\"].replace(\".csv\",\"_intercepts.yaml\") \n",
    "    print(\"Saving file:\", output_name)\n",
    "    with open(output_name, \"w\") as f:\n",
    "        f.write(\n",
    "            HEADSTRING.format(\n",
    "                file   = kwargs[\"filename\"],\n",
    "                raw_data = kwargs[\"x_data\"],\n",
    "                min = kwargs[\"min\"], \n",
    "                max = kwargs[\"max\"],\n",
    "                mean= kwargs[\"mean\"], \n",
    "                std = kwargs[\"std\"] \n",
    "                )\n",
    "            )\n",
    "        yaml.dump(\n",
    "            df.rename(\n",
    "                columns={\n",
    "                    # The name required for a histogram fit with the script\n",
    "                    # \"run_phyFit.py\"\n",
    "                    \"dx\":\"raw_data\", \n",
    "                    }\n",
    "                ).dropna().to_dict(orient=\"list\"), \n",
    "                f\n",
    "            )   \n",
    "main(\n",
    "    # Name of the input file\n",
    "    filename=\"data_raw.csv\", \n",
    "    # Name of the column to dump to yaml as \"x_data\" (in case)\n",
    "    x_data=\"Time (s)\", \n",
    "    # Name of the column to dump to yaml as \"y_data\" (in case)\n",
    "    y_data=\"Linear Acceleration x (m/s^2)\", \n",
    "    # Minimum for fitting -- potentially adjust by plotting\n",
    "    min=1.57,\n",
    "    # Maximum for fitting -- potentially adjust by plotting\n",
    "    max=1.63,\n",
    "    # Mean for fitting -- potentially adjust by plotting\n",
    "    mean=1.60,\n",
    "    # Standard deivation for fitting -- potentially adjust by plotting\n",
    "    std=0.004,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aff643-751a-4b28-88f7-7edde91e61ef",
   "metadata": {},
   "source": [
    "**Diskussion:**\n",
    "\n",
    " * Das Skript ließt die Datei ```data_raw.csv``` ein und findet den Nullstellendurchgang dort, wo die Funktion $f$ ($\\varphi$ aus der Angabe) ihr Vorzeichen wechselt. An diesen Stellen wird jewels $x$ ausgelesen. \n",
    "\n",
    " * Alle ermittelten Nullstellen werden in eine *yaml*-Datei geschrieben. \n",
    "\n",
    " * Auf diese Art und Weise können wir die Verteilung der Nulldurchgänge darstellen und Erwartungswert und Standardabweichung durch Anpassung einer Gauß-Funktion bestimmen. Wir haben ein bisschen mit den Möglichkeiten das Skript ```run_phyFit.py``` zu konfigurieren herumgespielt und **Abbildung 2** zu unserer Auswertung zugefügt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888cf1a-b1f2-448e-a86d-b8145ddce28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run /opt/conda/bin/run_phyFit.py ./yaml/data_raw_intercepts.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db465292-6037-4bf0-9147-c32008887a1c",
   "metadata": {},
   "source": [
    "**Abbildung 2** (Verteilung aller Perioden in der Datei `data_raw.csv`, bestimmt aus den ermittelten Nulldurchgängen, die wir in der Datei `data_raw_intercepts.yaml` gespeichert haben. An die Verteilung wurde eine Normalverteilung angepasst)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356d160-237f-43ad-ac20-817f9a709054",
   "metadata": {},
   "source": [
    " * Als einzelne Referenzmessung haben wir uns den Wert aus **Zeile 49 aus der Datei `data_raw_intercepts.yaml`** ausgewählt: \n",
    "\n",
    "$$\n",
    "T = (1.5951\\pm0.0178)\\,\\mathrm{s}.\n",
    "$$\n",
    "\n",
    " * $\\Delta T$ haben wir mit $\\sqrt{2}\\cdot 0.0125\\,\\mathrm{s}$ abgeschätzt. Das entspricht der Unsicherheit $\\Delta x$ auf einen Wert in $x$, aus der Datei ```./params/uncertainties_data.py```, mit einem zusätzlichen Faktor $\\sqrt{2}$ versehen, weil wir zwei Werte in $x$ voneinander abziehen (klassische lineare Fehlerfortpflanzung). \n",
    " * Die Werte für $\\ell$ und $\\Delta \\ell$ erhalten wir aus der Datei ```./params/parameters_Aufgabe_2.py```. Wir verwenden $\\ell$ als den Abstand des Schwerpunkts des Smartphones vom Aufhängepunkt des Pendels. \n",
    "\n",
    " * Wir bestimmen den Wert $g$ im folgenden Abschnitt:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277de36d-560b-4e1c-abe4-d1472c7b1b98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CODE TO CREATE REFERENCE RESULT G_12\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from params.parameters_Aufgabe_2 import l, l_UPPER, l_LOWER\n",
    "dl=(l_UPPER-l_LOWER)/2\n",
    "\n",
    "def gmath(T,dT):\n",
    "    \"\"\"\n",
    "    g for the mathematical pendulum in m/s**2. \n",
    "    \n",
    "    T   : Measured value, \n",
    "    dT  : Uncertainty in T.\n",
    "    \"\"\"\n",
    "    g = 4*np.pi**2/T/T*l\n",
    "    # Nothing fancy, linear error propagation assuming \n",
    "    # uncorrelated uncertainty sources\n",
    "    dg= np.sqrt(\n",
    "            (g/l*dl)**2            # Uncertainty on l\n",
    "          + (-2*g/T*dT)**2         # Uncertainty on T\n",
    "        )\n",
    "    return (g,dg)\n",
    "\n",
    "print(\"Reference result (Aufgabe 2.1):\\n\")\n",
    "g21 = gmath(1.59583, 0.0178)\n",
    "print(\"g21=\", g21[0], \"+/-\", g21[1])\n",
    "# This is g_exp: 'exp' stands for 'expected' in this context\n",
    "gexp=9.809599\n",
    "print(\"gexp=\", gexp)\n",
    "print(\"g21/gexp=\", g21[0]/gexp)\n",
    "# This is the cited uncertainty on g_exp; we calculate the \n",
    "# statistical pull from it. For this we assume that the \n",
    "# uncertainties on g21 and gexp are uncorrelated \n",
    "dgexp=0.000034\n",
    "print(\"pull=\", (g21[0]-gexp)/np.sqrt(g21[1]**2+dgexp**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049c47e2-32b0-4e22-8157-8d65fdd636a2",
   "metadata": {},
   "source": [
    "**Zusammenfassung:**\n",
    "\n",
    " * Den ermittelten Messwert von $g$ bezeichnen wir im Folgenden mit $g^{(2.1)}$. Ein Vergleich von $g^{(2.1)}$ mit dem gegebenen Referenzwert ist im folgenden zusammengefasst: \n",
    "    - $g^{(2.1)} = (9.74\\pm0.22)\\,\\mathrm{m/s^{2}}$\n",
    "    - $g_{\\mathrm{exp}} = (9.809599\\pm0.000034)\\,\\mathrm{m/s^{2}}$\n",
    "    - $g^{(2.1)}/g_{\\mathrm{exp}} = 0.993$\n",
    "    - $\\delta\\left(g^{(2.1)},g_{\\mathrm{exp}}\\right) = -0.31$\n",
    "\n",
    "   <br>Dabei bezeichnet $\\delta\\left(g^{(2.1)},g_{\\mathrm{exp}}\\right)$ den *Pull*\n",
    "   \n",
    "$$\n",
    "\\delta\\left(g^{(2.1)},g_{\\mathrm{exp}}\\right)=\\frac{g^{(2.1)}-g_{\\mathrm{exp}}}{\\sqrt{\\Delta g^{(2.1)2} + \\Delta g_{\\mathrm{exp}}^{2}}}\n",
    "$$\n",
    "\n",
    " * Ein relativer Unterschied $<1\\%$ beeindruckt. Aussagekräftiger ist jedoch der sogenannte *Pull* $\\delta$. Dabei handelt es sich um die Differenz aus Messung und Erwartung geteilt durch die Unsicherheit auf die Differenz, die wir wiederum durch lineare Fehlerfortpflanzung aus den Unsicherheiten der Messung und der Erwartung bestimmt haben. Für eine Erwartung, die mit der Messung kompatibel ist erwarten wir einen *Pull* von $\\delta\\lesssim1$. **Ein Wert von $\\delta=-0.31$ ist sehr zufriedenstellend**. \n",
    "\n",
    " * Zusammenfassend stellen wir eine **gute Übereinstimmung der Messung mit der Erwartung** fest! Wir überlegen allerding, ob wir $\\Delta g^{(2.1)}$ nicht noch ein bisschen verbessern können.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc03489f-5813-4d7d-b309-fbdb56a3879b",
   "metadata": {},
   "source": [
    "### Aufgabe 2.2: Erste Verbesserung der Methodik \n",
    "\n",
    " * Bestimmen Sie $T$ aus einer Anpassung an alle Datenpunkte, bestehend aus den Wertepaaren $\\left(t,\\varphi(t)\\right)$. Berücksichtigen Sie dabei die Unsicherheiten sowohl auf $t$, als auch auf $\\varphi(t)$. Angaben zu diesen Unsicherheiten können Sie z.B. der Datei [Datenblatt.md](https://gitlab.kit.edu/kit/etp-lehre/p1-praktikum/students/-/blob/main/Vorversuch/Datenblatt.md) entnehmen. Stellen Sie die Daten und das angepasste Modell geeignet graphisch dar. \n",
    " * Notieren Sie die folgenden wichtigen Ausgaben der Anpassung: \n",
    "    * Qualität der Anpassung (quantifiziert durch die Größe $\\hat{\\chi}^{2}/n_{\\mathrm{dof}}$) \n",
    "    * Die ermittelten Werte mit entsprechenden Unsicherheiten für alle an die Daten angepassten Parameter. \n",
    " * Berechnen Sie aus den bestimmten Werten für $T$ und $\\Delta T$ verbesserte Abschätzungen für $g^{(2.2)}$ und $\\Delta g^{(2.2)}$. Bestimmen Sie $\\Delta g^{(2.2)}$ mit Hilfe linearer [Fehlerfortpflanzung](https://de.wikipedia.org/wiki/Fehlerfortpflanzung) nach Gauß. Berücksichtigen Sie dabei auch die Unsicherheit $\\Delta\\ell$.\n",
    " * Vergleichen Sie Ihr Ergebnis, im Rahmen der Unsicherheiten, mit $g_{\\mathrm{exp}}$. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c004499-188e-4d8e-8b8d-6bd6a89a3b88",
   "metadata": {},
   "source": [
    "## Lösung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0246be05-bea6-421a-9df6-e101b4596a54",
   "metadata": {},
   "source": [
    " * Für diese Aufgabe verwenden wir die **Anpassung einer harmonischen Schwingung an die 10 Perioden** aus der Datei `data_down_sampled.csv`. Dabei gehen wir wie folgt vor: \n",
    "\n",
    " * Zunächst konvertieren wir die *csv*- in eine *yaml*-Datei: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc139bb-4325-41a1-a548-1f9475239e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /opt/conda/bin/csv2yml.py data_down_sampled.csv -s -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e699a8-8f89-4109-8703-e566361409e3",
   "metadata": {},
   "source": [
    " * Aus der Datei, die wir erhalten haben, benötigen wir nur die beiden Blöcke (siehe **Aufgabe 1**):\n",
    "\n",
    "   - '\"Time (s)\"' -- `x_data`\n",
    "\n",
    "   - '\"Linear Acceleration x (m/s^2)\"' -- `y_data`.\n",
    "\n",
    " * Wir haben die Blöcke zu den entsprechenden Schlüsselbegriffen `x_data` und `y_data` umbenannt, um sie mit dem Skript `run_phyFit.py` verwenden zu können.  \n",
    "\n",
    " * Zuletzt haben wir den folgenden Block *per Hand* zugefügt, um dem Skript Achsenbeschriftungen, Unsicherheiten und das anzupassende Modell bekannt zu machen. Die Unsicherheiten haben wir wieder aus der Datei `parameters/uncertainties_data.py`bezogen:\n",
    " \n",
    "```yaml\n",
    "# -----------------------------------------------------------------------------\n",
    "# Input data:\n",
    "# input file  : data_down_sampled.csv\n",
    "# x_data      : Time (s)\n",
    "# y_data      : Linear Acceleration x (m/s^2)\n",
    "# -----------------------------------------------------------------------------\n",
    "model_label: \"HARMONIC\"\n",
    "\n",
    "model_function: |\n",
    "  def model(x, x0=0.75, T=1.59, phi0=0.):\n",
    "      return x0*np.cos(2*np.pi/T*x+phi0)\n",
    "\n",
    "y_label: \"AU\"\n",
    "y_errors: 0.02\n",
    "\n",
    "x_errors: 0.0125\n",
    "x_label: \"t (s)\"\n",
    "...\n",
    "``` \n",
    "\n",
    " * Die Datei haben wir als `data_down_sampled_T_HARMONIC.yaml` im Verzeichnis `yaml` hinterlget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c9993-d0bd-4ae1-a90f-5a07ec5da25c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run /opt/conda/bin/run_phyFit.py ./yaml/data_down_sampled_T_HARMONIC.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8cfb63-12cf-486b-a052-4ba0c6fb5562",
   "metadata": {},
   "source": [
    "**Abbildung 3** (Anpassung des Modells einer harmonischen Schwingung (T_HARMONIC) an die Datenpunkte der Datei `data_down_sampled.yaml`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d266384-3250-4bed-857d-4b26346d7d12",
   "metadata": {},
   "source": [
    " * Die angepassten Parameter und ihre Unsicherheiten werden von der Anpassung zurückgegeben. Sie können aber auch aus **Abbildung 3** abgelesen werden. Wir geben sie hier als **wichtige Zwischenergebnisse für Aufgabe 2.2** tabellarisch an: \n",
    "\n",
    "| Parameter  | Wert  | Unsicherheit $\\Delta$  |\n",
    "|------------|-------|---------------|\n",
    "| $x_{0}$    | $0.778$               | $\\pm0.0027$  |\n",
    "| $\\phi_{0}$ | $-2.78$                | $\\pm0.015$  |\n",
    "| $T$        | $1.59583\\,\\mathrm{s}$ | $\\pm0.00042\\,\\mathrm{s}$  |\n",
    "\n",
    " * Für die Werte, die wir in Formeln weiterverwenden wollen notieren wir $1{-}2$ signifikante Stellen mehr. Dies ist in unserem Fall für $T$ und $\\Delta T$ der Fall. \n",
    "\n",
    " * Für die **Güte der Anpassung** erhalten wir den folgenden Wert:\n",
    " \n",
    "$$\n",
    "\\hat{\\chi}^{2}/n_{\\mathrm{dof}}=204.7/168.\n",
    "$$ \n",
    "\n",
    " * Unter Annahme einer $\\chi^{2}$-Verteilung mit 168 Freiheitsgraden entspricht dies einem ***p*-Wert von 2.8%**. Der *p*-Wert sagt aus, wie groß die Wahrscheinlichkeit ist, bei einem solchen Experiment, wie diesem einen Ausgang von $\\chi^{2}>\\hat{\\chi}^{2}$ zu erhalten. Um uns den Zusammenhang zwischen $\\hat{\\chi}^{2}$ und *p*-Wert nochmal klarzu machen, haben wir die Werte, die wir erhalten haben in diesem [*p*-value calculator](http://courses.atlas.illinois.edu/spring2016/STAT/STAT200/pchisq.html) der Universität Illinois nochmal veranschaulicht.   \n",
    " \n",
    " * Dieser Wert erscheint ernüchternd niedrig. Das könnte ein Hinweis darauf sein kann, dass das zugrundeliegende Modell (T_HARMONIC) die Daten nicht gut beschreibt. Allerdings würde man bei häufiger Wiederholung einer solchen Messung erwarten, in $2.8\\%$ aller Ausgänge einen *p*-Wert $\\leq 2.8\\%$ zu erhalten, *selbst wenn* die Daten, dem Erwartungswert nach, wirklich dem Verlauf des Modells folgen. \n",
    "\n",
    " * Mit Hilfe der Werte für $T$ und $\\Delta T$ berechnen wir $g$ neu und bezeichnen diesen Wert im Folgenden als $g^{(2.2)}$:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61bbc8-cb64-48eb-8a65-fb2c7774193f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CODE TO CREATE REFERENCE RESULT G_22\n",
    "\"\"\"\n",
    "print(\"Improved result (Aufgabe 2.2):\\n\")\n",
    "g22 = gmath(1.5958, 0.00042)\n",
    "print(\"g22=\", g22[0], \"+/-\", g22[1])\n",
    "print(\"gexp=\", gexp)\n",
    "print(\"g22/gexp=\", g22[0]/gexp)\n",
    "print(\"pull=\", (g22[0]-gexp)/np.sqrt(g22[1]**2+dgexp**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0328fc-1175-4ca9-b8d8-01e63a1da4cb",
   "metadata": {},
   "source": [
    "**Zusammenfassung:**\n",
    "\n",
    " * Der Vergleich von $g^{(2.2)}$ mit unserer Erwartung ist im folgenden zusammengefasst:  \n",
    "\n",
    "   - $g^{(2.2)} = (9.743\\pm0.0093)\\,\\mathrm{m/s^{2}}$\n",
    "\n",
    "   - $g^{(2.2)}/g_{\\mathrm{exp}} = 0.993$\n",
    "\n",
    "   - $\\delta\\left(g^{(2.2)},g_{\\mathrm{exp}}\\right) = -7.1$\n",
    "\n",
    " * Wie zuvor weicht diese Messung nur um $0.7\\%$ von der Erwartung ab. **Ein *Pull* von $\\delta\\left(g^{(2.2)},g_{\\mathrm{exp}}\\right)=-7.1$ kann aber nicht ignoriert** werden! Wir müssen zusammenfassend feststellen, dass diese Abweichung im Rahmen der angegebenen Unsicherheiten nur sehr schwer durch eine statistische Fluktuation zu erklären ist, d.h. sie ist signifikant. \n",
    "\n",
    " * Das zugrundeliegende Modell ist vermutlich zu einfach, um die Realität vollständig abbilden zu können. Dies ist eine Unzulänglichkeit und damit ein (vermeidbarer) **Fehler** der bisherigen Auswertung. Dieser Fehler wurde bei der Referenzmessung aus **Aufgabe 2.1** durch den großen Wert von $\\Delta T$ überdeckt. Durch die deutlich präzisere Bestimmung von $T$ tritt er jetzt offen zutage.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3dddf5-da68-44df-aaf5-7b5272160273",
   "metadata": {},
   "source": [
    "### Aufgabe 2.3: Zweite Verbesserung der Methodik\n",
    "\n",
    " * Bestimmen Sie $g^{(2.3)}$ und $\\Delta g^{2.3}$ direkt aus der Anpassung. Formulieren Sie ihre Modellfunktion dazu entsprechend um, führen Sie die Anpassung erneut durch und vergleichen Sie die Ergebnisse für $g^{(2.3)}$ und $\\Delta g^{(2.3)}$ mit den Ergebnissen aus **Aufgabe 2.2**. \n",
    " * Überlegen Sie, wie Sie in diesem Fall $\\Delta\\ell$ im Ergebnis von $\\Delta g^{(2.3)}$ berücksichtigen können.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03f75b-8ee5-4835-a98d-337cf7b29602",
   "metadata": {},
   "source": [
    "## Lösung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7de9c-b3c9-47ef-9074-d63e7ccd132b",
   "metadata": {},
   "source": [
    " * Um $g$ **direkt aus der Anpassung an die Daten bestimmen** zu können haben wir das Modell T_HARMONIC wie folgt modifiziert und in G_HARMONIC umbenannt:\n",
    "\n",
    "```yaml\n",
    "# -----------------------------------------------------------------------------\n",
    "# Input data:\n",
    "# input file  : data_down_sampled.csv\n",
    "# x_data      : Time (s)\n",
    "# y_data      : Linear Acceleration x (m/s^2)\n",
    "# -----------------------------------------------------------------------------\n",
    "model_label: \"G_HARMONIC\"\n",
    "\n",
    "model_function: |\n",
    "  def model(x, x0=0.75, g=9.8, phi0=0):\n",
    "      return x0*np.cos(np.sqrt(g/0.6285)*x+phi0)\n",
    "y_label: \"AU\"\n",
    "y_errors: 0.02\n",
    "\n",
    "x_errors: 0.0125\n",
    "x_label: \"t (s)\"\n",
    "...\n",
    "```\n",
    "\n",
    " * Bei dem fest ins Modell kodierten Zahlenwert (0.6285) handelt es sich um den angegebenen Wert von $\\ell$ aus der Datei: ```params/parameters_Aufgabe_2.py```. \n",
    " \n",
    " * Wir haben dieses Modell in der Datei `data_down_sampled_G_HARMONIC.yaml` im Verzeichnis `yaml` hinterleget und die Anpassung an die Daten erneut durchgeführt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089af586-2c62-406b-8469-dd390e897eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run /opt/conda/bin/run_phyFit.py ./yaml/data_down_sampled_G_HARMONIC.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3cdb8e-7bed-4771-bb47-f1a9f955fdc5",
   "metadata": {},
   "source": [
    "**Abbildung 4** (Anpassung des Modells G_HARMONIC, aus dem wir $g$ direkt ablesen können, an die Datenpunkte der Datei `data_down_sampled.yaml`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ca955-335e-4162-94f4-a22b13c74d8c",
   "metadata": {},
   "source": [
    " * Der aus der Anpassung ermittelte Wert von $g$, den wir im Weiteren mit $g^{(2.3)}$ bezeichnen werden, beträgt\n",
    "\n",
    "$$\n",
    "g^{(2.3)} = 9.743\\,\\mathrm{m/s^{2}}\n",
    "$$\n",
    "\n",
    " * Wir stellen fest, dass der bestimmte Zentralwert von $g^{(2.3)}$ **mit den Ergebnis von Aufgabe 2.2 identisch** ist. Dies entspricht genau unserer Erwartung, da es sich bei dem oben verwendeten Modell nur um eine **Umparametrisierung des Modells von Aufgabe 2.2** handelt. \n",
    "\n",
    " * Interessanter ist die Beobachtung, dass die Unsicherheit (die wir weiterhin mit $\\Delta g^{(2.3)}_{\\mathrm{stat.}}$ bezeichnen werden) deutlich kleiner ausfällt, als dies für **Aufgabe 2.2** der Fall war. \n",
    " \n",
    " * Das liegt daran, dass $\\Delta g^{(2.3)}_{\\mathrm{stat.}}$ nur die Unsicherheiten berücksichtigt, die ganz konkret mit den Messpunkten aus der Datei `data_down_sampled.csv` verbunden sind. \n",
    "\n",
    " * Würden wir eine solche Messung unter ansonsten identischen Bedingungen wiederholen, würden die Datenpunkte einer entsprechenden neuen Datei innerhalb der angegebenen Unsicherheiten fluktuieren. Diese Art von Unsicherheiten bezeichnen wir in der Physik als **statistische Unsicherheiten**. \n",
    "\n",
    " * Die Unsicherheit $\\Delta \\ell$ auf den Parameter $\\ell$, den wir aus der Datei `parameters/parameters_Aufgabe_2.py` ausgelesen haben, findet bisher noch keine Berücksichtigung. Bei $\\ell$ handelt es sich um einen **externen Parameter des zugrundeliegenden Modells**. Um $\\Delta \\ell$ ebenfalls zu berücksichtigen haben wir grundsätzlich zwei Möglichkeiten: \n",
    "   * Wir fügen $\\Delta\\ell$ durch lineare Fehlerfortpflanzung, wie in **Aufgabe 2.2** zu.\n",
    "   \n",
    "   * Um uns die Propagation des Effekts von $\\Delta \\ell$ auf $g^{(2.3)}$ zu ersparen, wiederholen wir die Anpassung ($2\\times$) mit variierten Werten von $\\ell\\pm\\Delta\\ell$. Daraus erhalten wir einen Wert $\\Delta g^{(2.3)}_{\\mathrm{syst.}}$ den wir quadratisch zu $\\Delta g^{(2.3)}_{\\mathrm{stat.}}$ addieren. Wir bezeichnen $\\Delta g^{(2.3)}_{\\mathrm{syst.}}$ als **systematische Unsicherheit**. In der Physik sind systematische Unsicherheiten grundsätzlich mit systematischen Variationen, wie wir sie hier durchgeführt haben, verbunden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d8673-cccb-418c-a1e2-ca58f1e63eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CODE TO OBTAIN THE UNCERTAINTIES FOR G_23\n",
    "\"\"\"\n",
    "print(\"Split by stat. and syst. uncertainty (Aufgabe 2.3):\\n\")\n",
    "g23_upper = 9.7507\n",
    "g23_lower = 9.7352\n",
    "g23_syst  = abs(g23_upper-g23_lower)/2\n",
    "print(\"Delta g23 (stat)=+/- 0.005\")\n",
    "print(\"Delta g23 (syst)=+/-\",g23_syst)\n",
    "print(\"Delta g23 (comb)=+/-\", np.sqrt(0.005**2+g23_syst**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db02a16-72fa-48de-b9e3-d9730d820f8b",
   "metadata": {},
   "source": [
    " * Nach diesem Vorgehen erhalten wir die folgenden Ergebnisse: \n",
    "\n",
    "   * $\\Delta g^{(2.3)}_{\\mathrm{stat.}} = 0.005\\,\\mathrm{m/s^{2}}$\n",
    "   * $\\Delta g^{(2.3)}_{\\mathrm{syst.}} = 0.008\\,\\mathrm{m/s^{2}}$\n",
    "   * $\\Delta g^{(2.3)} = 0.009\\,\\mathrm{m/s^{2}}$\n",
    " \n",
    "   <br>und daraus das Gesamtergebnis: \n",
    "\n",
    "$$\n",
    "g^{(2.3)} = (9.743\\pm0.005\\,(\\mathrm{stat.})\\pm0.008\\,(\\mathrm{syst.}))\\,\\mathrm{m/s^{2}}\n",
    "$$\n",
    "\n",
    " * Einschließlich(!) der angegebenen Unsicherheiten stimmt dieses Ergebnis genau mit dem Ergebnis aus **Aufgabe 2.2** überein. \n",
    "\n",
    " * Der $\\hat{\\chi}^{2}/n_{\\mathrm{dof}}$-Wert ist ebenfalls unverändert niedrig. Es ist allerdings auch nicht zu erwarten, dass sich dieser Wert ändert, da das Modell, bis auf die Umparametrisierung, ebenfalls unverändert geblieben ist. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d108978-f0b0-4c4f-8222-68b7b2096082",
   "metadata": {},
   "source": [
    "## Aufgabe 3: Schrittweise Erweiterung des Modells\n",
    "\n",
    "**Hinweise zu allen hier durchzuführenden Messungen finden Sie in der Datei [Hinweise-Aufgabe-3.md](https://gitlab.kit.edu/kit/etp-lehre/p1-praktikum/students/-/tree/main/Vorversuch/doc/Hinweise-Aufgabe-3.md).**\n",
    "\n",
    "Eine offensichtliche Unzulänglichkeit des vorherigen Modells besteht in der Vernachlässigung der endlichen Ausdehnung des Pendels. Wenn Sie das Modell entsprechend erweitern, nimmt die Formel zur Bestimmung von $g$ die folgende Form an: \n",
    "\n",
    "$$\n",
    "g = \\frac{4\\,\\pi^{2}}{T^{2}}\\frac{\\Theta}{Ms},\n",
    "$$\n",
    "\n",
    "wobei $\\Theta$ und $M$ dem Trägheitsmoment und der Masse der gesamten Pendelkonstruktion (einschließlich aller Montageteile und Smartphone!) und $s$ dem Abstand zwischen dem Schwerpunkt und der Aufhängung des Pendels entsprechen.\n",
    "\n",
    "### Aufgabe 3.1: Erste Erweiterung des Modells \n",
    "\n",
    " * Modifizieren Sie Ihr Modell, so dass es dem Modell eines [physikalischen Pendels](https://de.wikipedia.org/wiki/Physikalisches_Pendel) entspricht und machen Sie eine neue Abschätzung für $g^{(3.1)}$ und $\\Delta g^{(3.1)}$. \n",
    " * Schätzen Sie den Einfluss von $\\Delta\\Theta$, $\\Delta M$, und $\\Delta s$ auf $\\Delta g^{(3.1)}$ ab und überlegen Sie, wie Sie diese Unsicherheiten geeignet zu einer Gesamtunsicherheit kombinieren können.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf89b23-d8a8-4c8c-a1a4-ea60b14a43c1",
   "metadata": {},
   "source": [
    "## Lösung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011015a6-31fb-481b-9e1f-67e6399c6043",
   "metadata": {},
   "source": [
    " * Um die physikalische Ausdehnung des Pendels zu berücksichtigen haben wir das Modell aus **Aufgabe 2.3** wie folgt abgeändert: \n",
    "\n",
    "```yaml\n",
    "# -----------------------------------------------------------------------------\n",
    "# Input data:\n",
    "# input file  : data_down_sampled.csv\n",
    "# x_data      : Time (s)\n",
    "# y_data      : Linear Acceleration x (m/s^2)\n",
    "# -----------------------------------------------------------------------------\n",
    "model_label: \"G_HARMONIC_NEW\"\n",
    "\n",
    "model_function: |\n",
    "  def model(x, x0=0.75, g=9.8, phi0=0):\n",
    "      return x0*np.cos(np.sqrt(0.789*0.473*g/0.23523)*x+phi0)\n",
    "y_label: \"AU\"\n",
    "y_errors: 0.02\n",
    "\n",
    "x_errors: 0.0125\n",
    "x_label: \"t (s)\"\n",
    "...\n",
    "```\n",
    "\n",
    " * Bei den fest ins Modell kodierten Zahlenwerten handelt es sich nun um die angegebenen Werte von $\\Theta$, $M$, und $s$ aus der Datei: ```params/parameters_Aufgabe_3.py```. \n",
    " \n",
    " * Wir haben dieses Modell in der Datei `data_down_sampled_G_HARMONIC_NEW.yaml` im Verzeichnis `yaml` hinterlegt und die Anpassung an die Daten erneut durchgeführt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae874ed4-8316-49ff-aaef-c85e246d0593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run /opt/conda/bin/run_phyFit.py ./yaml/data_down_sampled_G_HARMONIC_NEW.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82750d3c-a05c-46d9-9990-0d212db21778",
   "metadata": {},
   "source": [
    "**Abbildung 5** (Anpassung des Modells G_HARMONIC_NEW, in dem die endliche Ausdehnung des Pendels berücksichtigt ist, an die Datenpunkte der Datei `data_down_sampled.yaml`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719c4dd-416f-49c5-9394-627a7bdad3c3",
   "metadata": {},
   "source": [
    " * Wir stellen fest, dass sich der aus der Anpassung ermittelte Wert von $g$, den wir weiterhin mit $g^{(3.1)}$ bezeichnen werden, im Vergleich zu **Aufgabe 2** verändert hat. Er beträgt nun <br>\n",
    "$$\n",
    "g^{(3.1)} = (9.771\\pm0.005\\,(\\mathrm{stat.}))\\,\\mathrm{m/s^{2}}\n",
    "$$\n",
    "   <br>und ist damit etwas näher an unsere Erwartung gerückt. \n",
    "   \n",
    " * Die Unsicherheit $\\Delta g^{(3.1)}_{\\mathrm{stat.}}$ ist mit den Ergebnis von **Aufgabe 2.3** identisch. Dies ist wiederum nicht verwunderlich, denn bis auf einen Skalenfaktor an $g$ ist das Modell nach wie vor unverändert, weshalb wir auch nach wie vor den gleichen niedrigen *p*-Wert für die Anpassung erhalten, wie zuvor. \n",
    "\n",
    " * **Unsere Hoffnung, dass sich durch das realistischere Modell die Beschreibung unserer Daten verbessern würde hat sich daher zerschlagen.**\n",
    "\n",
    " * Zur Abschätzung der Unsicherheiten $\\Delta\\Theta$, $\\Delta M$ und $\\Delta s$ gehen wir analog zu **Aufgabe 2.3** vor. Dazu haben wir die Anpassung $6\\times$ mit variierten Parametern durchgeführt und $g^{(3.1)}$ jeweils neu daraus bestimmt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ec73c-2a01-4d3e-ac88-62a56c3b6414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CODE TO OBTAIN THE UNCERTAINTIES FOR G_31\n",
    "\"\"\"\n",
    "print(\"Split by stat. and syst. uncertainties (Aufgabe 3.1):\\n\")\n",
    "# Estimates for Theta\n",
    "g31_T_upper = 9.8778\n",
    "g31_T_lower = 9.6701\n",
    "g31_T_syst  = abs(g31_T_upper-g31_T_lower)/2\n",
    "# Estimates for M\n",
    "g31_M_upper = 9.7095\n",
    "g31_M_lower = 9.8333\n",
    "g31_M_syst  = abs(g31_M_upper-g31_M_lower)/2\n",
    "# Estimates for s\n",
    "g31_s_upper = 9.6285\n",
    "g31_s_lower = 9.9178\n",
    "g31_s_syst  = abs(g31_s_upper-g31_s_lower)/2\n",
    "# Combination\n",
    "g31_syst = np.sqrt(g31_T_syst**2+g31_M_syst**2+g31_s_syst**2)\n",
    "g31_comb = np.sqrt(g31_syst**2+0.005**2)\n",
    "print(\"Delta g31        (stat)=+/- 0.005\")\n",
    "print(\"Delta g31(Theta) (syst)=+/-\",g31_T_syst)\n",
    "print(\"Delta g31(M)     (syst)=+/-\",g31_M_syst)\n",
    "print(\"Delta g31(s)     (syst)=+/-\",g31_s_syst)\n",
    "print(\"Delta g31        (syst)=+/-\",g31_syst)\n",
    "print(\"Delta g31 (comb)=+/-\", g31_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f807e5c-7163-4c23-a2c2-8a1bddb39672",
   "metadata": {},
   "source": [
    " * Wir stellen fest, das $\\Delta g^{(31)}_{\\mathrm{syst.}}$ (mit einem Wert von $\\pm0.19\\,(\\mathrm{stat.}\\,\\mathrm{m/s^{2}}$) **unter dem neuen und vermeitlich *besseren* Modell um ein Vielfaches größer geworden** ist als zuvor. Die Messung ist durch die neu eingeführten systematischen Unsicherheiten vollkommen dominiert. \n",
    " \n",
    " * Das enttäuscht zunächst: Wir haben ein komplizierteres Modell, das uns bei der Beschreibung der Daten nicht weitergeholfen hat, und zu allem Überfluss ist unsere Messung trotz aller Bemühungen nur um ein Weniges genauer, als die Referenzmessung aus **Aufgabe 2.1**.\n",
    "\n",
    " * Tatsächlich hat das neue Modell aber Unsicherheitsquellen offen gelegt, die zuvor nicht offensichtlich waren: \n",
    "   * Als dominante Unsicherheitsquellen erweisen sich $\\Delta\\Theta$ und $\\Delta s$. Das ist sofort ersichtlich, wenn man bedenkt, dass beide Größen zum einen großen Einfluss auf die Messgröße $g$ haben und zum anderen schwierig zu bestimmen sind.\n",
    "   \n",
    "   * In das einfache Modell aus **Aufgabe 2** konnten diese Unsichereiten garnicht abgebildet werden.\n",
    "\n",
    " * Wir fassen an dieser Stelle noch einmal den Vergleich mit unserer Erwartung zusammen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed7f63-8362-4eb3-9cc8-28483658f6ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CODE TO COMPARE THE RESULT OF G31 WITH OUR EXPECTATION\n",
    "\"\"\"\n",
    "print(\"Improved result (Aufgabe 3.1):\\n\")\n",
    "g31=9.771\n",
    "print(\"g31=\"+str(g31)+\"+/-\"+str(g31_syst))\n",
    "print(\"gexp=\", gexp)\n",
    "print(\"g22/gexp=\", g31/gexp)\n",
    "print(\"pull=\", (g31-gexp)/np.sqrt(g31_comb**2+dgexp**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220395c1-127a-4ad5-8025-1906e64539ef",
   "metadata": {},
   "source": [
    "**Zusammenfassung:**\n",
    "\n",
    " * Der Vergleich von $g^{(3.1)}$ mit unserer Erwartung ist im folgenden zusammengefasst:  \n",
    "\n",
    "   - $g^{(3.1)} = (9.77\\pm0.19)\\,\\mathrm{m/s^{2}}$\n",
    "\n",
    "   - $g^{(3.1)}/g_{\\mathrm{exp}} = 0.996$\n",
    "\n",
    "   - $\\delta(g^{(3.1)},g_{\\mathrm{exp}}) = -0.2$\n",
    "\n",
    " * Mit einem *Pull* von -0,20 stellen wir tatsächlich bessere Konsistenz zwischen dem gemessenen Wert und der Erwartung fest, als in den vorherigen Fällen. \n",
    " \n",
    " * Dies ist kein Taschenspielertrick, so als hätten wir die systematischen Unsicherheiten nur so lange erhöht, bis wir Übereinstimmung mit der Ewartung erzielt hätten. Tatsächlich sind die mit dieser Messmethode verbundenen systematischen Unsicherheiten so groß, dass sich der Wert von $g$ nicht genauer angeben lässt. Diesen Umstand hat das Modell aus **Aufgabe 2**, aufgrund seiner Einfachheit, nicht abbilden können.\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c9aa44-f73e-47e0-bc1b-40719329b77e",
   "metadata": {},
   "source": [
    "### Aufgabe 3.2: Zweite Erweiterung des Modells\n",
    "\n",
    "Das Pendel erfährt in seiner Bewegung zusätzlich eine Dämpfung. Wenn Sie der Messung das Modell einer [linearer gedämpften Schwingung](https://de.wikipedia.org/wiki/Schwingung#Linear_ged%C3%A4mpfte_Schwingung) zugrunde legen verändert sich die Formel zur Bestimmung von $g$ wie folgt: \n",
    "\n",
    "$$\n",
    "g = \\left(\\frac{4\\,\\pi^{2}}{T^{2}}+\\frac{1}{\\tau^{2}}\\right)\\frac{\\Theta}{Ms},\n",
    "$$\n",
    "\n",
    "wobei $\\tau$ einer Abklingzeit der Schwingungsamplitude in Sekunden entspricht. Wie Sie sehen handelt es sich um eine Korrektur, die die Abschätzung von $g$ zu größeren Werten hin verändert. \n",
    "\n",
    "Verändern Sie ihr Modell geeignet und beantworten Sie die folgenden Fragen: \n",
    "  * Kann das zugrundeliegende Modell die Daten beschreiben? \n",
    "  * Wie könnten Sie die Hypothese, dass das zugrundeliegende Modell die Daten beschreiben kann, noch besser testen? \n",
    "  * Wie groß ist der Effekt der Korrektur aus der obigen Gleichung auf die Messung von $g$? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03929c0b-fba2-40e2-b796-8f2066a376db",
   "metadata": {},
   "source": [
    "## Lösung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a4a7fe-e381-4b8d-8e5b-35c1162c6db0",
   "metadata": {},
   "source": [
    " * Im nächsten Schritt erweitern wir das Modell um den Umstand, dass die Schwingung des Pendels gedämpft wird. Wir versuchen es mit einem Modell mit linearer Dämpfung. Ein solches Modell führt zu einer Schwingung der Form:<br><br>\n",
    "$$\n",
    "\\varphi(t) = \\varphi_{0}\\,e^{-t/\\tau}\\cos\\left(\\sqrt{\\frac{M\\,s}{\\Theta}\\,g-\\frac{1}{\\tau^{2}}}\\,t + \\phi\\right),\n",
    "$$\n",
    "<br>wobei $\\tau$ ein weiterer zu bestimmender Parameter der Anpassung wird.\n",
    "\n",
    " * Wir haben das Modell wie folgt verändert und in der Datei `./yaml/data_down_sampled_G_DAMPED.yaml` hinterlegt:\n",
    "\n",
    "```yaml\n",
    "# -----------------------------------------------------------------------------\n",
    "# Input data:\n",
    "# input file  : data_down_sampled.csv\n",
    "# x_data      : Time (s)\n",
    "# y_data      : Linear Acceleration x (m/s^2)\n",
    "# -----------------------------------------------------------------------------\n",
    "model_label: \"G_DAMPED\"\n",
    "\n",
    "model_function: |\n",
    "  def model(x, tau=240., x0=0.75, g=9.8, phi0=0):\n",
    "      return x0*np.exp(-x/tau)*np.cos(np.sqrt(0.789*0.473*g/0.23523-1./tau**2)*x+phi0)\n",
    "\n",
    "y_label: \"AU\"\n",
    "y_errors: 0.02\n",
    "\n",
    "x_errors: 0.0125\n",
    "x_label: \"t (s)\"\n",
    "...\n",
    "```\n",
    "\n",
    " * Aus der erneuten Anpassung erhalten wir das folgende Ergebnis der Anpassung: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e01bd-46cd-4c1b-9076-8656aa8b2114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run /opt/conda/bin/run_phyFit.py yaml/data_down_sampled_G_DAMPED.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168dda6f-275a-4173-a283-852876352cd0",
   "metadata": {},
   "source": [
    "**Abbildung 6** (Anpassung des Modells G_DAMPED, unter Berücksichtigung eines linearen Dämpfungsterms der Schwingung, an die Datenpunkte der Datei `data_down_sampled.yaml`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33363a2f-ed86-4792-ad14-6f79491548cd",
   "metadata": {},
   "source": [
    " * Wir stellen mit Befriedigung fest, dass diese Änderung tatsächlich zu einer Verbesserung des $\\hat{\\chi}^{2}/n_{\\mathrm{ndof}}$-Werts führt. **Der entsprechende *p*-Wert steigt von 2,8% auf 35,1%!** Wir haben also den Freiheitsgrad gefunden, der dem Modell fehlte, um die Daten wirklich im Rahmen der angegebenen Unsicherheiten beschreiben zu können. \n",
    " \n",
    " * Tatsächlich kann man dem Modell ansehen, dass es die Daten besser beschreibt, als zuvor. Die Beschreibung sah zuvor aber auch nicht unbedingt schlecht auf. Auf das Urteil des Auges sollte man sich in solchen Fällen also nicht unbedingt verlassen. \n",
    " \n",
    " * Wir stellen ferner fest, dass bei der Bestimmung des $\\hat{\\chi}^{2}/n_{\\mathrm{ndof}}$-Wertes einen Freiheitsgrad weniger auftaucht, als zuvor (vgl. z.B. **Abbildung 5**). Dies ist dem zusätzlichen Modellparameter $\\tau$ geschuldet. \n",
    " \n",
    " * Weiterhin stellen wir fest, dass sich der Wert von $g^{(3.2)}$ kaum von $g^{(3.1)}$ unterscheidet. Durch kurze Rechnung überzeugen wir uns von de Größe des Effekts, den $\\tau$ auf die Bestimmung von $g^{(3.2)}$ hat:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa076a-c48b-4fcc-b17d-02309d0d9555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from params.parameters_Aufgabe_3 import Theta, M, s\n",
    "\n",
    "tau=245\n",
    "print(\"Delta g32=\",Theta/M/s/tau**2, \"m/s**2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d656c-b112-499e-9298-d30d86dd41f0",
   "metadata": {},
   "source": [
    " * Wir stellen fest, dass der Effekt für den vorliegenden Wert von $\\tau$ tatsächlich nur von der Größenordnung $\\mathcal{O}(10^{-5}\\,\\mathrm{m/s^{2}})$ ist, er spielt also für unsere Betrachtungen keine Rolle. \n",
    " \n",
    " * Wir fragen uns noch, warum die Änderung von $g^{(3.2)}$ relativ zu $g^{(3.1)}$ dann doch im Bereich von $\\mathcal{O}(10^{-4}\\,\\mathrm{m/s^{2}})$ liegt (also 10-mal größer ist). Wir vermuten, dass dies der Einfluss der geringen negativen Korrelation zwischen $\\tau$ und $g$ ist, die wir aus der Ausgabe der Anpassung ablesen können. Keine Dämpfung ist gleichbedeutend mit $\\tau\\to\\infty$. Da $\\tau=245\\pm53\\,\\mathrm{s}<\\infty$ hat das einen erhöhenden Einfluss auf $g$.  \n",
    " \n",
    " * Auf diesem Datensatz haben wir die Bedeutung von $\\tau$ für eine gute Beschreibung der Daten nicht sofort erkannt. Auf einem größeren Datensatz über einen längeren Messzeitraum ($\\mathcal{O}(5\\,\\mathrm{min})$), wäre die Notwengikeit für $\\tau$ offensichtilich geworden. \n",
    " \n",
    " * Eine gute Beschreibung der Daten hat sich für diese Messung als nicht absolut notwendig erwiesen, da $\\tau$ eben nur sehr geringen Einfluss auf $g$ hat. Grundsätzlich ist es jedoch immer vorzuziehen eine gute Beschreibung der Daten zu erzielen. \n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b9b49-c48c-4317-a04d-83ccd0811f31",
   "metadata": {},
   "source": [
    "## Bonusaufgabe: Vom Messen zur Kunst\n",
    "\n",
    "Ein bewusst formuliertes Modell zur Behandlung der Unsicherheiten, die in eine Parameterschätzung eingehen, ist Bestandteil eines guten statistischen Modells. Die Diskussion über die Berücksichtigung der Unsicherheiten der Modellparameter $\\Theta$, $M$ und $s$, bei der Bestimmung von $g$ und $\\Delta g$ in **Aufgabe 3.1** wirft eine Frage auf, die wir im Rahmen dieses Vorversuchs bisher nur streifen konnten: Wie sind die Unsicherheiten auf die äußeren Parameter der Messung korreliert? Sie können die folgenden Bonusaufgaben bearbeiten, um dieser Frage weiter nachzugehen. Die Bearbeitung ist jedoch nicht verpflichtend.\n",
    "\n",
    "### Bonusaufgabe 1: Korrelierte Unsicherheiten\n",
    "\n",
    "Jede Variation eines der drei Parameter $\\Theta$, $M$ oder $s$ in **Aufgabe 3.1** hat einen nicht-trivialen Einfluss, nicht nur auf $g$, sondern auch auf die jeweils anderen äußeren Parameter. Durch naive, quadratische Addition von $\\Delta \\Theta$, $\\Delta M$, und $\\Delta s$ unterlegen Sie (vielleicht unbewusst) die Annahme, das alle drei Variationen paarweise unabhängig sind. Diese Annahme ist auf jeden Fall falsch! Ein anderes Modell, dass Sie anwenden könnten, wäre zwei oder alle Parameter vollständig zu korrelieren. Was bedeutet diese Annahme für die Variation der Parameter? Denken, Sie dass diese Annahme korrekt ist? Machen Sie einen Vorschlag zur Lösung dieses Problems. \n",
    "\n",
    "### Bonusaufgabe 2: Experimentelle Verbesserung der Messung \n",
    "\n",
    "Diskutieren Sie, wie dieser Versuch konzeptionell verbessert werden könnte, um die in Bonusaufgabe 1 diskutierten Probleme von vornherein zu vermeiden.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5614cf5-68ff-4ade-837c-6055a2944e95",
   "metadata": {},
   "source": [
    " * Wir stellen zunächst fest, dass $\\Delta\\Theta$, $\\Delta M$ und $\\Delta s$ wirklich nicht unabhängig voneinander sein können. Wenn z.B. die Position der Halterung für das Smartphone falsch bestimmt wurde hat dies Einfluss auf $\\Theta$ und $s$ gleichermaßen. Ebenso, hat es Einfluss auf $\\Theta$, $s$ und $M$, wenn die Masse des Smartphones flasch bestimmt wurde. \n",
    " \n",
    " * Wir könnten z.B. annehmen, dass die Variationen von $\\Delta\\Theta$ und $\\Delta s$ zu 100% korreliert sind. Das würde bedeuten, dass eine Variation von `g31_T_upper/lower` gleichzeitig mit einer Variation von `g31_s_upper/lower` durchzuführen wäre. In einem Modell, in dem man $\\Delta\\Theta$ und $\\Delta s$ als zu 100% korreliert aber unabhängig von $\\Delta M$ annimmt, würde man den so gewonnen Wert quadratisch zu `g31_M_syst` addieren. Diese Annahmen sind aber mit Sicherheit auch nicht korrekt. \n",
    " \n",
    " * Man kann teilweise Korrelationen zwischen zwei Unsicherheiten $\\Delta X$ und $\\Delta Y$ einführen, indem man z.B. $\\Delta X$ durch quadratische Subtraktion eines Anteil zerlegt und einen der beiden Anteile gemeinsam mit $\\Delta Y$ variiert. \n",
    " \n",
    " * Was in diesem Fall zu einem besseren, wenngleich nicht unkomplizierten Modell für die Unsicherheiten führen würde, ist nach den zugrundeliegenden unabhängigen Ursachen für $\\Delta\\Theta$, $\\Delta M$ und $\\Delta s$ zu suchen. Aus diesen ließen sich dann auch die entsprechenden Korrelationen ableiten. Für die Berechnug von $\\Delta g$ würde man die zugrundeliegenden, unabhängigen Ursachen direkt variieren können. Für unseren Fall wären dies z.B. die Masse des Smartphones und die Unsicherheit auf die Position am Pendel. Beide Größen sind sicher unabhängig voneinander.  \n",
    " \n",
    " * Abschließend lässt sich sagen, dass eine Bestimmung von $g$ mit Hilfe komplizierter Konstruktionen, deren Trägheitsmomente und Schwerpunkte zu bestimmen sind sicher nicht die beste Methode zur Bestimmung von $g$ darstellt. \n",
    " \n",
    "    * Im Versuch [Kreisel](https://gitlab.kit.edu/kit/etp-lehre/p1-praktikum/students/-/tree/main/Kreisel) werden Sie eine Technik kennenlernen, wie Sie mit Hilfe einfacher Körper, deren Trägheitsmoment einfach zu berechnen ist die *Berechnung* der Trägheitsmomente des Kardankreisels umgehen können.   \n",
    "    \n",
    "    * Im Versuch [Pendel](https://gitlab.kit.edu/kit/etp-lehre/p1-praktikum/students/-/tree/main/Pendel) werden Sie mit dem Reversionspendel einen Aufbau kennenlernen, mit dem Sie $g$ ganz ohne Kenntnis von $\\Theta$ oder $s$ bestimmen können! Dabei handelt es sich i.ü. um genau das gleiche Pendel, das wir für diesen Versuch verwendet haben.  \n",
    " \n",
    " * Grundsätzlich ist man immer besser dran, wenn man eine Größe direkt messen kann und sich nicht auf Berechnungen verlassen muss, deren Annahmen nicht immer offensichtlich sind. \n",
    " \n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
